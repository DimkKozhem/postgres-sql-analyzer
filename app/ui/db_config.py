"""–ú–æ–¥—É–ª—å –¥–ª—è –≤–∫–ª–∞–¥–∫–∏ '–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î' —Å LLM."""

import streamlit as st
import json
import logging
from typing import Dict, Any, List
import pandas as pd

logger = logging.getLogger(__name__)


def show_db_config_tab(dsn: str, mock_mode: bool = False):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≤–∫–ª–∞–¥–∫—É '–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ë–î'."""
    st.markdown("## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")

    if mock_mode:
        st.info("üé≠ Mock —Ä–µ–∂–∏–º: –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
        _show_mock_db_config()
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL
        pg_settings = _get_pg_settings(dsn)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        _show_pg_settings(pg_settings)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        _show_critical_parameters(pg_settings)

        # LLM –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        _show_llm_analysis(pg_settings)

        # –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞
        _show_export_options(pg_settings)

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ë–î: {str(e)}")
        logger.error(f"–û—à–∏–±–∫–∞ –≤ show_db_config_tab: {e}")


def _get_pg_settings(dsn: str) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL."""
    import psycopg2

    settings = []

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ RealDictCursor –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º)
        conn = psycopg2.connect(dsn)
        conn.autocommit = True

        with conn.cursor() as cur:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            cur.execute("""
                    SELECT 
                        name,
                        setting,
                        unit,
                        category,
                        short_desc,
                        context,
                        vartype,
                        min_val,
                        max_val,
                        enumvals,
                        boot_val,
                        reset_val,
                        source,
                        sourcefile,
                        sourceline
                    FROM pg_settings
                    ORDER BY category, name
                """)

            columns = [desc[0] for desc in cur.description]
            rows = cur.fetchall()

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            for row in rows:
                settings.append(dict(zip(columns, row)))

        conn.close()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ PostgreSQL: {e}")
        raise

    return settings


def _show_pg_settings(settings: List[Dict[str, Any]]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL."""
    st.markdown("### üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL")

    if not settings:
        st.warning("‚ö†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –°–æ–∑–¥–∞–µ–º DataFrame
    settings_df = pd.DataFrame(settings)

    # –§–∏–ª—å—Ç—Ä—ã
    col1, col2 = st.columns(2)

    with col1:
        categories = ['–í—Å–µ'] + sorted(settings_df['category'].unique().tolist())
        selected_category = st.selectbox("–ö–∞—Ç–µ–≥–æ—Ä–∏—è", categories)

    with col2:
        search_term = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é", placeholder="work_mem, shared_buffers...")

    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    filtered_df = settings_df.copy()

    if selected_category != '–í—Å–µ':
        filtered_df = filtered_df[filtered_df['category'] == selected_category]

    if search_term:
        filtered_df = filtered_df[filtered_df['name'].str.contains(search_term, case=False, na=False)]

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
    st.dataframe(
        filtered_df[['name', 'setting', 'unit', 'category', 'short_desc']],
        width='stretch',
        hide_index=True,
        column_config={
            'name': '–ü–∞—Ä–∞–º–µ—Ç—Ä',
            'setting': '–ó–Ω–∞—á–µ–Ω–∏–µ',
            'unit': '–ï–¥–∏–Ω–∏—Ü–∞',
            'category': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            'short_desc': '–û–ø–∏—Å–∞–Ω–∏–µ'
        }
    )

    st.info(f"üìä –ü–æ–∫–∞–∑–∞–Ω–æ {len(filtered_df)} –∏–∑ {len(settings_df)} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")


def _show_critical_parameters(settings: List[Dict[str, Any]]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."""
    st.markdown("### ‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    critical_params = [
        'work_mem', 'shared_buffers', 'effective_cache_size',
        'maintenance_work_mem', 'checkpoint_completion_target',
        'wal_buffers', 'max_connections', 'autovacuum',
        'random_page_cost', 'seq_page_cost', 'cpu_tuple_cost',
        'cpu_index_tuple_cost', 'cpu_operator_cost'
    ]

    critical_settings = [s for s in settings if s['name'] in critical_params]

    if not critical_settings:
        st.warning("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    critical_df = pd.DataFrame(critical_settings)

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π
    for _, setting in critical_df.iterrows():
        col1, col2, col3 = st.columns([2, 1, 3])

        with col1:
            st.write(f"**{setting['name']}**")

        with col2:
            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
            status = _get_parameter_status(setting)
            if status == 'good':
                st.success(f"‚úÖ {setting['setting']} {setting.get('unit', '')}")
            elif status == 'warning':
                st.warning(f"‚ö†Ô∏è {setting['setting']} {setting.get('unit', '')}")
            else:
                st.error(f"‚ùå {setting['setting']} {setting.get('unit', '')}")

        with col3:
            st.caption(setting.get('short_desc', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'))


def _get_parameter_status(setting: Dict[str, Any]) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (good/warning/error)."""
    name = setting['name']
    value = setting['setting']

    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
    if name == 'work_mem':
        try:
            val = int(value)
            if val < 4:
                return 'warning'
            elif val > 256:
                return 'warning'
            else:
                return 'good'
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ {setting['name']}: {e}")
            return 'error'

    elif name == 'shared_buffers':
        try:
            val = int(value)
            if val < 128:
                return 'warning'
            elif val > 2048:
                return 'warning'
            else:
                return 'good'
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ {setting['name']}: {e}")
            return 'error'

    elif name == 'max_connections':
        try:
            val = int(value)
            if val > 200:
                return 'warning'
            else:
                return 'good'
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ {setting['name']}: {e}")
            return 'error'

    return 'good'


def _show_llm_analysis(settings: List[Dict[str, Any]]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç LLM –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ."""
    st.markdown("### ü§ñ AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ AI
    if not st.session_state.get('enable_ai', False):
        st.info("‚ÑπÔ∏è AI –∞–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª—é—á–µ–Ω. –í–∫–ª—é—á–∏—Ç–µ AI –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.")
        return

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if 'db_config_analyzed' not in st.session_state:
        with st.spinner("ü§ñ AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é..."):
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM
                critical_settings = _prepare_settings_for_llm(settings)

                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LLM
                recommendations = _get_llm_recommendations(critical_settings)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ session_state
                st.session_state['db_config_analysis'] = recommendations
                st.session_state['db_config_analyzed'] = True

            except Exception:
                st.error("‚ùå –û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞")
                logger.error("–û—à–∏–±–∫–∞ LLM –∞–Ω–∞–ª–∏–∑–∞")
                st.session_state['db_config_analyzed'] = True

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if 'db_config_analysis' in st.session_state:
        _display_llm_recommendations(st.session_state['db_config_analysis'])
    
    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑", help="–ü–æ–≤—Ç–æ—Ä–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"):
        st.session_state['db_config_analyzed'] = False
        st.rerun()


def _prepare_settings_for_llm(settings: List[Dict[str, Any]]) -> Dict[str, Any]:
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è LLM –∞–Ω–∞–ª–∏–∑–∞."""
    critical_params = [
        'work_mem', 'shared_buffers', 'effective_cache_size',
        'maintenance_work_mem', 'max_connections', 'autovacuum'
    ]

    critical_settings = {}
    for setting in settings:
        if setting['name'] in critical_params:
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ None –∑–Ω–∞—á–µ–Ω–∏–π
            value = str(setting['setting']).strip() if setting['setting'] is not None else ''
            unit = str(setting.get('unit', '')).strip() if setting.get('unit') is not None else None
            description = str(setting.get('short_desc', '')).strip() if setting.get('short_desc') is not None else ''

            critical_settings[setting['name']] = {
                'value': value,
                'unit': unit,
                'description': description
            }

    return critical_settings


def _get_llm_recommendations(settings: Dict[str, Any]) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LLM."""
    try:
        import asyncio
        from app.llm_integration import LLMIntegration

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
        api_key = st.session_state.get('openai_api_key', '')
        if not api_key:
            return {
                'recommendations': """‚ùå **OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω**

üí° **–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á:**
1. –û—Ç–∫—Ä–æ–π—Ç–µ sidebar (–ª–µ–≤–∞—è –ø–∞–Ω–µ–ª—å)
2. –ù–∞–π–¥–∏—Ç–µ —Ä–∞–∑–¥–µ–ª "ü§ñ AI –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
3. –í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API –∫–ª—é—á –≤ –ø–æ–ª–µ "OpenAI API –∫–ª—é—á"
4. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é" —Å–Ω–æ–≤–∞

üîó **–ì–¥–µ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:**
- –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://platform.openai.com/api-keys
- –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á
- –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

‚öôÔ∏è **–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
- –ú–æ–¥–µ–ª—å: {st.session_state.get('openai_model', 'gpt-4o-mini')}""",
                'settings_analyzed': settings
            }

        # –°–æ–∑–¥–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é PostgreSQL –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

        –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
        {json.dumps(settings, indent=2, ensure_ascii=False)}

        –ù–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

        ### –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –≤—ã—Å–æ–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–Ω–∏–∑–∫–∏–π
        –ö–∞—Ç–µ–≥–æ—Ä–∏—è: configuration_optimization/maintenance_optimization/query_optimization
        –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è
        –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: –û–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π
        –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0.0-1.0

        ---

        –î–∞–π 3-5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.
        """

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
        llm_config = {
            'openai_api_key': api_key,
            'openai_model': st.session_state.get('openai_model', 'gpt-4o-mini'),
            'openai_temperature': st.session_state.get('openai_temperature', 0.7),
            'enable_proxy': st.session_state.get('enable_proxy', True),
            'proxy_host': st.session_state.get('proxy_host', 'localhost'),
            'proxy_port': st.session_state.get('proxy_port', 1080)
        }

        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–±–µ–∑ API –∫–ª—é—á–∞)
        logger.info(f"LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: –º–æ–¥–µ–ª—å={llm_config['openai_model']}, "
                    f"–ø—Ä–æ–∫—Å–∏={llm_config['enable_proxy']}, "
                    f"—Ö–æ—Å—Ç={llm_config['proxy_host']}:{llm_config['proxy_port']}")

        llm = LLMIntegration(llm_config)

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π execution_plan –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        mock_execution_plan = {
            'type': 'configuration_analysis',
            'settings': settings,
            'prompt': prompt
        }

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        async def get_async_recommendations():
            return await llm.get_recommendations(
                sql_query=prompt,
                execution_plan=mock_execution_plan,
                db_schema=settings
            )

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        recommendations = asyncio.run(get_async_recommendations())

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        if recommendations:
            formatted_recommendations = "## ü§ñ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL\n\n"
            for rec in recommendations:
                formatted_recommendations += f"### {rec.description}\n"
                formatted_recommendations += f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {rec.priority}\n"
                formatted_recommendations += f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {rec.category}\n"
                formatted_recommendations += f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {rec.reasoning}\n"
                if rec.expected_improvement:
                    formatted_recommendations += f"**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** {rec.expected_improvement}\n"
                formatted_recommendations += f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {rec.confidence:.2f}\n\n"
        else:
            formatted_recommendations = "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç AI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API –∫–ª—é—á–µ–π –∏ –ø—Ä–æ–∫—Å–∏."

        return {
            'recommendations': formatted_recommendations,
            'settings_analyzed': settings
        }

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è LLM —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}"

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
        if "401" in str(e) or "unauthorized" in str(e).lower():
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö sidebar"
        elif "403" in str(e) or "forbidden" in str(e).lower():
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** API –∫–ª—é—á –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ OpenAI API"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ API –∫–ª—é—á–∞"
        elif "httpx" in str(e):
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ httpx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ httpx: `pip install httpx[socks]`"
        elif "proxy" in str(e).lower():
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–æ–∫—Å–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏ –≤ sidebar"
        elif "timeout" in str(e).lower():
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –ø—Ä–æ–∫—Å–∏"
        else:
            error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
            error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API –∫–ª—é—á–∞ –∏ –ø—Ä–æ–∫—Å–∏"

        return {
            'recommendations': error_msg,
            'settings_analyzed': settings
        }


def _display_llm_recommendations(recommendations: Dict[str, Any]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ LLM."""
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations_text = recommendations['recommendations']

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ
    has_header = (
        recommendations_text.startswith("## ")
        or "## ü§ñ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏" in recommendations_text
        or "ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI" in recommendations_text
        or recommendations_text.startswith("### ")
    )

    if not has_header:
        st.markdown("#### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç JSON –±–ª–æ–∫–∏
    import re
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', recommendations_text, re.DOTALL)

    if json_match:
        # –ï—Å–ª–∏ –µ—Å—Ç—å JSON –±–ª–æ–∫, –∏–∑–≤–ª–µ–∫–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –µ–≥–æ
        try:
            import json
            json_str = json_match.group(1)
            data = json.loads(json_str)

            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            for i, rec in enumerate(data.get("recommendations", []), 1):
                priority_emoji = {
                    "high": "üî¥",
                    "medium": "üü°",
                    "low": "üü¢"
                }.get(rec.get("priority", "medium"), "üü°")

                category_emoji = {
                    "configuration_optimization": "‚öôÔ∏è",
                    "maintenance_optimization": "üîß",
                    "query_optimization": "üîç",
                    "connection_management": "üîó",
                    "general": "üìã"
                }.get(rec.get("category", "general"), "üìã")

                st.markdown(f"### {priority_emoji} {rec.get('description', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è')}")

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {rec.get('priority', 'medium')}")
                    st.markdown(f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {category_emoji} {rec.get('category', 'general')}")
                with col2:
                    st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {rec.get('confidence', 0.0):.2f}")

                if rec.get('current_query') and rec.get('current_query') != 'N/A':
                    st.markdown(f"**–¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:** `{rec.get('current_query')}`")

                if rec.get('optimized_query'):
                    st.markdown(f"**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:** `{rec.get('optimized_query')}`")

                if rec.get('expected_improvement'):
                    st.markdown(f"**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** {rec.get('expected_improvement')}")

                if rec.get('reasoning'):
                    st.markdown(f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {rec.get('reasoning')}")

                st.markdown("---")

        except Exception:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å JSON, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            st.markdown(recommendations_text)
    else:
        # –ï—Å–ª–∏ –Ω–µ Markdown –∏ –Ω–µ JSON, –ø–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        _parse_structured_text(recommendations_text)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    with st.expander("üìã –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"):
        settings = recommendations['settings_analyzed']

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        if settings:
            st.markdown("**–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã PostgreSQL:**")

            for param_name, param_data in settings.items():
                st.markdown(f"**{param_name}:**")
                st.markdown(f"- –ó–Ω–∞—á–µ–Ω–∏–µ: `{param_data['value']}` {param_data['unit'] or ''}")
                st.markdown(f"- –û–ø–∏—Å–∞–Ω–∏–µ: {param_data['description']}")
                st.markdown("---")
        else:
            st.info("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")


def _parse_structured_text(text: str):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∫–∞–∫ Markdown."""
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    text = text.replace("ü§ñ AI –∞–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã", "").strip()
    text = text.replace("üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", "").strip()
    text = text.replace("ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ PostgreSQL", "").strip()
    text = text.replace("## ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ PostgreSQL", "").strip()
    text = text.replace("## ü§ñ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL", "").strip()

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ
    import re
    text = re.sub(r'## ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ PostgreSQL\s*', '', text)
    text = re.sub(r'## ü§ñ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL\s*', '', text)
    text = re.sub(r'ü§ñ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ PostgreSQL\s*', '', text)
    text = re.sub(r'### AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL\s*', '', text)

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º "---"
    recommendations = []

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ "---"
    parts = text.split('---')

    for part in parts:
        part = part.strip()
        if not part:
            continue

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —ç–º–æ–¥–∑–∏
        part = re.sub(r'^üü°\s*', '', part)
        part = re.sub(r'^üî¥\s*', '', part)
        part = re.sub(r'^üü¢\s*', '', part)

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–ª–∏ –º—É—Å–æ—Ä
        if (part.strip()
            and not part.startswith('##')
            and not part.startswith('–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ AI')
            and '–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:' in part  # –î–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–µ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                and len(part.strip()) > 50):  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –≤–∞–ª–∏–¥–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations.append(part.strip())

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:"
    if not recommendations:
        current_rec = ""
        lines = text.split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:" - —ç—Ç–æ –∫–æ–Ω–µ—Ü —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:" in line:
                current_rec += line + "\n"
                if current_rec.strip():
                    recommendations.append(current_rec.strip())
                current_rec = ""
            else:
                current_rec += line + "\n"

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        if current_rec.strip():
            recommendations.append(current_rec.strip())

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–∞–∂–¥—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
    for rec_text in recommendations:
        if rec_text.strip():
            _display_single_recommendation_clean(rec_text)


def _display_single_recommendation_clean(text: str):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–¥–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ —á–∏—Å—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    if not text.strip():
        return

    # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–π –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    import re

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è
    text = re.sub(r'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:\s*\*\*\s*([^*]+)\s*\*\*', r'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: \1', text)
    text = re.sub(r'–ö–∞—Ç–µ–≥–æ—Ä–∏—è:\s*[üìã‚öôÔ∏è]\s*\*\*\s*([^*]+)\s*\*\*', r'–ö–∞—Ç–µ–≥–æ—Ä–∏—è: \1', text)
    text = re.sub(r'–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:\s*\*\*\s*([^*]+)\s*\*\*', r'–û–±—ä—è—Å–Ω–µ–Ω–∏–µ: \1', text)
    text = re.sub(r'–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:\s*\*\*\s*([^*]+)\s*\*\*', r'–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: \1', text)

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–≤–µ–∑–¥–æ—á–∫–∏
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ —Ç–æ—á–∫–∏)
    title_match = re.match(r'^([^.]*\.)', text)
    title = title_match.group(1).strip() if title_match else text.split('.')[0].strip()

    # –û—á–∏—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    title = re.sub(r'^[üü°üî¥üü¢]\s*', '', title)
    title = title.strip()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
    priority_emoji = "üü°"
    if any(word in title.lower() for word in ['—É–≤–µ–ª–∏—á–∏—Ç—å', 'increase', '–∫—Ä–∏—Ç–∏—á–Ω–æ', 'critical', '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è', 'optimization']):
        priority_emoji = "üî¥"
    elif any(word in title.lower() for word in ['–ø—Ä–æ–≤–µ—Ä–∏—Ç—å', 'check', '—Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å', 'consider', '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞']):
        priority_emoji = "üü¢"

    st.markdown(f"### {priority_emoji} {title}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞
    priority_match = re.search(r'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:\s*([^–ö\n]+?)(?=\s*–ö–∞—Ç–µ–≥–æ—Ä–∏—è:|$)', text)
    category_match = re.search(r'–ö–∞—Ç–µ–≥–æ—Ä–∏—è:\s*([^–û\n]+?)(?=\s*–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:|$)', text)
    explanation_match = re.search(r'–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:\s*([^–û\n]+?)(?=\s*–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:|$)', text)
    improvement_match = re.search(r'–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:\s*([^–£\n]+?)(?=\s*–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:|$)', text)
    confidence_match = re.search(r'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:\s*([0-9.,]+)', text)

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
    col1, col2 = st.columns(2)

    with col1:
        if priority_match:
            priority = priority_match.group(1).strip()
            st.markdown(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}")

        if category_match:
            category = category_match.group(1).strip()
            category_emoji = "‚öôÔ∏è" if "configuration" in category.lower() or "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è" in category.lower() else "üìã"
            st.markdown(f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {category_emoji} {category}")

    with col2:
        if confidence_match:
            confidence = confidence_match.group(1).strip()
            st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {confidence}")

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ –æ–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
    if explanation_match:
        explanation = explanation_match.group(1).strip()
        st.markdown(f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {explanation}")

    if improvement_match:
        improvement = improvement_match.group(1).strip()
        st.markdown(f"**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** {improvement}")

    st.markdown("---")


def _display_single_recommendation_simple(text: str):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–¥–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ –ø—Ä–æ—Å—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    if not text.strip():
        return

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ —Ç–æ—á–∫–∏)
    import re
    title_match = re.match(r'^([^.]*\.)', text)
    title = title_match.group(1).strip() if title_match else text.split('.')[0].strip()

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
    priority_emoji = "üü°"
    if any(word in title.lower() for word in ['—É–≤–µ–ª–∏—á–∏—Ç—å', 'increase', '–∫—Ä–∏—Ç–∏—á–Ω–æ', 'critical']):
        priority_emoji = "üî¥"
    elif any(word in title.lower() for word in ['–ø—Ä–æ–≤–µ—Ä–∏—Ç—å', 'check', '—Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å', 'consider']):
        priority_emoji = "üü¢"

    st.markdown(f"### {priority_emoji} {title}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞
    priority_match = re.search(r'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:\s*([^–ö]+?)(?=\s*–ö–∞—Ç–µ–≥–æ—Ä–∏—è:|$)', text)
    category_match = re.search(r'–ö–∞—Ç–µ–≥–æ—Ä–∏—è:\s*([^–û]+?)(?=\s*–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:|$)', text)
    explanation_match = re.search(r'–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:\s*([^–û]+?)(?=\s*–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:|$)', text)
    improvement_match = re.search(r'–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:\s*([^–£]+?)(?=\s*–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:|$)', text)
    confidence_match = re.search(r'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:\s*([0-9.,]+)', text)

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
    col1, col2 = st.columns(2)

    with col1:
        if priority_match:
            priority = priority_match.group(1).strip()
            st.markdown(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}")

        if category_match:
            category = category_match.group(1).strip()
            category_emoji = "‚öôÔ∏è" if "configuration" in category.lower() else "üìã"
            st.markdown(f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {category_emoji} {category}")

    with col2:
        if confidence_match:
            confidence = confidence_match.group(1).strip()
            st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {confidence}")

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ –æ–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
    if explanation_match:
        explanation = explanation_match.group(1).strip()
        st.markdown(f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {explanation}")

    if improvement_match:
        improvement = improvement_match.group(1).strip()
        st.markdown(f"**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** {improvement}")

    st.markdown("---")


def _show_export_options(settings: List[Dict[str, Any]]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–ø—Ü–∏–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–∞."""
    st.markdown("### üì§ –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üìÑ –≠–∫—Å–ø–æ—Ä—Ç –≤ Markdown"):
            _export_to_markdown(settings)

    with col2:
        if st.button("üìä –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON"):
            _export_to_json(settings)

    with col3:
        if st.button("üìã –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV"):
            _export_to_csv(settings)


def _export_to_markdown(settings: List[Dict[str, Any]]):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ Markdown."""
    try:
        import pandas as pd

        settings_df = pd.DataFrame(settings)

        # –°–æ–∑–¥–∞–µ–º Markdown –æ—Ç—á–µ—Ç
        markdown_content = f"""# –û—Ç—á–µ—Ç –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL

## –°–≤–æ–¥–∫–∞
- –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {len(settings)}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(settings_df['category'].unique())}

## –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

"""

        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        critical_params = ['work_mem', 'shared_buffers', 'effective_cache_size']
        for param in critical_params:
            param_data = settings_df[settings_df['name'] == param]
            if not param_data.empty:
                setting = param_data.iloc[0]
                markdown_content += f"### {param}\n"
                markdown_content += f"- **–ó–Ω–∞—á–µ–Ω–∏–µ:** {setting['setting']} {setting.get('unit', '')}\n"
                markdown_content += f"- **–û–ø–∏—Å–∞–Ω–∏–µ:** {setting.get('short_desc', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')}\n\n"

        # –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        st.download_button(
            label="üíæ –°–∫–∞—á–∞—Ç—å Markdown",
            data=markdown_content,
            file_name="postgresql_config_report.md",
            mime="text/markdown"
        )

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Markdown: {str(e)}")


def _export_to_json(settings: List[Dict[str, Any]]):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ JSON."""
    try:
        json_content = json.dumps(settings, indent=2, ensure_ascii=False, default=str)

        st.download_button(
            label="üíæ –°–∫–∞—á–∞—Ç—å JSON",
            data=json_content,
            file_name="postgresql_config_report.json",
            mime="application/json"
        )

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ JSON: {str(e)}")


def _export_to_csv(settings: List[Dict[str, Any]]):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ CSV."""
    try:
        import pandas as pd

        settings_df = pd.DataFrame(settings)
        csv_content = settings_df.to_csv(index=False)

        st.download_button(
            label="üíæ –°–∫–∞—á–∞—Ç—å CSV",
            data=csv_content,
            file_name="postgresql_config_report.csv",
            mime="text/csv"
        )

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV: {str(e)}")


def _show_mock_db_config():
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ë–î."""
    st.markdown("### üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏ PostgreSQL (Mock –¥–∞–Ω–Ω—ã–µ)")

    # Mock –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    mock_settings = [
        {'name': 'work_mem', 'setting': '4', 'unit': 'MB', 'category': 'Resource Usage',
            'short_desc': 'Sets the base maximum amount of memory to be used by a query operation'},
        {'name': 'shared_buffers', 'setting': '128', 'unit': 'MB', 'category': 'Resource Usage',
            'short_desc': 'Sets the amount of memory the database server uses for shared memory buffers'},
        {'name': 'effective_cache_size', 'setting': '4', 'unit': 'GB', 'category': 'Query Tuning',
            'short_desc': 'Sets the planner\'s assumption about the effective size of the disk cache'},
        {'name': 'max_connections', 'setting': '100', 'unit': '', 'category': 'Connections and Authentication',
            'short_desc': 'Sets the maximum number of concurrent connections'}
    ]

    settings_df = pd.DataFrame(mock_settings)
    st.dataframe(settings_df, width='stretch', hide_index=True)

    st.markdown("### ‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (Mock)")

    for setting in mock_settings:
        col1, col2, col3 = st.columns([2, 1, 3])

        with col1:
            st.write(f"**{setting['name']}**")

        with col2:
            st.success(f"‚úÖ {setting['setting']} {setting['unit']}")

        with col3:
            st.caption(setting['short_desc'])

    st.markdown("### ü§ñ AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (Mock)")
    st.info("‚ÑπÔ∏è AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ mock —Ä–µ–∂–∏–º–µ")

    st.markdown("### üì§ –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ (Mock)")
    st.info("‚ÑπÔ∏è –≠–∫—Å–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ mock —Ä–µ–∂–∏–º–µ")
