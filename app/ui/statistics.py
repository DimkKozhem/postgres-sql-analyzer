"""–ú–æ–¥—É–ª—å –¥–ª—è –≤–∫–ª–∞–¥–∫–∏ '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'."""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, Any
import logging
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime, timedelta
import json

logger = logging.getLogger(__name__)


def show_statistics_tab(dsn: str, mock_mode: bool = False):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≤–∫–ª–∞–¥–∫—É '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞'."""
    st.markdown("## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    if mock_mode:
        st.info("üé≠ Mock —Ä–µ–∂–∏–º: –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
        _show_mock_statistics()
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_data = _get_statistics_data(dsn)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        _show_general_statistics(stats_data)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤
        _show_query_statistics(stats_data)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        _show_connection_statistics(stats_data)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏
        _show_load_charts(stats_data)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")
        logger.error(f"–û—à–∏–±–∫–∞ –≤ show_statistics_tab: {e}")


def _get_statistics_data(dsn: str) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    stats_data = {
        'general': {},
        'queries': [],
        'connections': [],
        'load_metrics': []
    }

    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        conn = psycopg2.connect(dsn, cursor_factory=RealDictCursor)

        with conn.cursor() as cur:
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cur.execute("""
                SELECT 
                    (SELECT count(*) FROM pg_stat_activity) as active_connections,
                    (SELECT count(*) FROM pg_stat_activity WHERE state = 'active') as active_queries,
                    (SELECT count(*) FROM pg_stat_activity WHERE state = 'idle') as idle_connections,
                    (SELECT count(*) FROM pg_stat_activity WHERE state = 'idle in transaction') as idle_in_transaction
            """)
            result = cur.fetchone()
            if result:
                stats_data['general'] = dict(result)

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ (PostgreSQL 17 —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
            cur.execute("""
                SELECT 
                    query,
                    calls,
                    total_exec_time,
                    mean_exec_time,
                    rows,
                    shared_blks_hit,
                    shared_blks_read,
                    shared_blks_dirtied,
                    shared_blks_written,
                    temp_blks_read,
                    temp_blks_written,
                    wal_records,
                    wal_bytes
                FROM pg_stat_statements 
                ORDER BY total_exec_time DESC 
                LIMIT 20
            """)
            queries = cur.fetchall()
            stats_data['queries'] = [dict(query) for query in queries]

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
            cur.execute("""
                SELECT 
                    datname,
                    usename,
                    application_name,
                    client_addr,
                    state,
                    query_start,
                    state_change,
                    backend_start,
                    query
                FROM pg_stat_activity 
                WHERE datname IS NOT NULL
                ORDER BY query_start DESC NULLS LAST
            """)
            connections = cur.fetchall()
            stats_data['connections'] = [dict(conn) for conn in connections]

            # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ –∏–∑ pg_stat_statements
            cur.execute("""
                SELECT 
                    calls,
                    total_exec_time,
                    mean_exec_time,
                    shared_blks_hit,
                    shared_blks_read,
                    temp_blks_read,
                    temp_blks_written
                FROM pg_stat_statements 
                WHERE calls > 0
                ORDER BY total_exec_time DESC
                LIMIT 100
            """)
            load_metrics = cur.fetchall()
            stats_data['load_metrics'] = [dict(metric) for metric in load_metrics]

        conn.close()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        pass

    return stats_data


def _show_general_statistics(stats_data: Dict[str, Any]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
    st.markdown("### üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

    general = stats_data.get('general', {})

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="üîó –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è",
            value=general.get('active_connections', 0)
        )

    with col2:
        st.metric(
            label="‚ö° –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã",
            value=general.get('active_queries', 0)
        )

    with col3:
        st.metric(
            label="üò¥ –ù–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è",
            value=general.get('idle_connections', 0)
        )

    with col4:
        st.metric(
            label="‚è≥ –í —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏",
            value=general.get('idle_in_transaction', 0)
        )


def _show_query_statistics(stats_data: Dict[str, Any]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤."""
    st.markdown("### üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤")

    queries = stats_data.get('queries', [])

    if not queries:
        st.info("‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–ø—Ä–æ—Å–∞—Ö (pg_stat_statements –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω)")
        return

    # –°–æ–∑–¥–∞–µ–º DataFrame
    queries_df = pd.DataFrame(queries)

    # –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    if not queries_df.empty:
        st.markdown("#### ‚è±Ô∏è –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        top_queries = queries_df.head(10).copy()
        top_queries['query_short'] = top_queries['query'].str[:50] + '...'

        fig_time = px.bar(
            top_queries,
            x='mean_exec_time',
            y='query_short',
            orientation='h',
            title="–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ (–º—Å)",
            labels={'mean_exec_time': '–í—Ä–µ–º—è (–º—Å)', 'query_short': '–ó–∞–ø—Ä–æ—Å'},
            color='mean_exec_time',
            color_continuous_scale='Reds'
        )
        fig_time.update_layout(
            height=500,
            yaxis={'categoryorder': 'total ascending'},
            showlegend=False,
            margin=dict(l=20, r=100, t=50, b=50)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã
        )
        fig_time.update_traces(
            hovertemplate='<b>%{y}</b><br>–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: %{x:.1f} –º—Å<extra></extra>',
            text=[f"{x:.1f} –º—Å" for x in top_queries['mean_exec_time']],  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å –≤—Ä–µ–º–µ–Ω–µ–º
            textposition='outside',
            textfont=dict(size=13, color='white', family='Arial')  # –ë–µ–ª—ã–µ —Ü–∏—Ñ—Ä—ã, —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        )
        st.plotly_chart(fig_time, width='stretch')

        # –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤—ã–∑–æ–≤–æ–≤
        st.markdown("#### üìû –¢–æ–ø –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤—ã–∑–æ–≤–æ–≤")

        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        calls_queries = queries_df.head(10).copy()
        calls_queries['query_short'] = calls_queries['query'].str[:45] + '...'

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã–∑–æ–≤–æ–≤
        total_calls = calls_queries['calls'].sum()
        calls_queries['calls_percentage'] = (calls_queries['calls'] / total_calls * 100).round(1)

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        fig_calls = px.bar(
            calls_queries,
            x='calls',
            y='query_short',
            orientation='h',
            title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤",
            labels={'calls': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤', 'query_short': '–ó–∞–ø—Ä–æ—Å'},
            color='calls',
            color_continuous_scale='Blues'
        )

        # –£–ª—É—á—à–∞–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        fig_calls.update_layout(
            height=600,
            yaxis={'categoryorder': 'total ascending'},
            showlegend=False,
            title_font_size=16,
            font=dict(size=12),
            margin=dict(l=20, r=100, t=50, b=50)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        fig_calls.update_traces(
            hovertemplate='<b>%{y}</b><br>'
            + '–í—ã–∑–æ–≤–æ–≤: %{x:,}<br>'
            + '–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ: %{customdata[0]}%<br>'
            + '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: %{customdata[1]:.1f} –º—Å<br>'
            + '–û–±—â–µ–µ –≤—Ä–µ–º—è: %{customdata[2]:.1f} –º—Å<extra></extra>',
            customdata=list(zip(
                calls_queries['calls_percentage'],
                calls_queries['mean_exec_time'],
                calls_queries['total_exec_time']
            ))
        )

        # –£–±–∏—Ä–∞–µ–º —Ü–∏—Ñ—Ä—ã —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        fig_calls.update_traces(
            text=None,  # –£–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
            textposition=None
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏
        max_calls = max(calls_queries['calls'])
        for i, row in calls_queries.iterrows():
            fig_calls.add_annotation(
                x=row['calls'] + max_calls * 0.03,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ—Ç—Å—Ç—É–ø
                y=row['query_short'],
                text=f"{row['calls_percentage']:.1f}%",  # –¢–æ–ª—å–∫–æ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
                showarrow=False,
                font=dict(size=13, color='#333333', family='Arial'),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
                xanchor='left',
                bgcolor='rgba(255,255,255,0.95)',  # –ï—â–µ –±–æ–ª–µ–µ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
                bordercolor='rgba(0,0,0,0.3)',
                borderwidth=1
            )

        st.plotly_chart(fig_calls, width='stretch')

        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä—É–≥–æ–≤—É—é –¥–∏–∞–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–∑–æ–≤–æ–≤
        st.markdown("##### ü•ß –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–∑–æ–≤–æ–≤")

        # –°–æ–∑–¥–∞–µ–º –∫—Ä—É–≥–æ–≤—É—é –¥–∏–∞–≥—Ä–∞–º–º—É –¥–ª—è —Ç–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤
        pie_data = calls_queries.head(5).copy()
        pie_data['query_label'] = pie_data['query'].str[:30] + '...'

        fig_pie = px.pie(
            pie_data,
            values='calls',
            names='query_label',
            title="–¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –≤—ã–∑–æ–≤–æ–≤",
            color_discrete_sequence=px.colors.qualitative.Set3
        )

        fig_pie.update_traces(
            textposition='inside',
            textinfo='percent+label',
            textfont=dict(size=14, family='Arial'),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –Ω–∞–¥–ø–∏—Å–µ–π
            hovertemplate='<b>%{label}</b><br>'
                         + '–í—ã–∑–æ–≤–æ–≤: %{value}<br>'
                         + '–ü—Ä–æ—Ü–µ–Ω—Ç: %{percent}<extra></extra>'
        )

        fig_pie.update_layout(
            height=500,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã—Å–æ—Ç—É –¥–∏–∞–≥—Ä–∞–º–º—ã
            showlegend=True,
            font=dict(size=14, family='Arial'),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
            legend=dict(
                orientation="v",
                yanchor="middle",
                y=0.5,
                xanchor="left",
                x=1.01,
                font=dict(size=12, family='Arial')  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ª–µ–≥–µ–Ω–¥—ã
            )
        )

        st.plotly_chart(fig_pie, width='stretch')

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—ã–∑–æ–≤–∞–º
        col1, col2, col3 = st.columns(3)

        with col1:
            most_called = calls_queries.iloc[0]
            st.metric(
                "üî• –°–∞–º—ã–π —á–∞—Å—Ç—ã–π –∑–∞–ø—Ä–æ—Å",
                f"{most_called['calls']:,} –≤—ã–∑–æ–≤–æ–≤",
                help=f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {most_called['mean_exec_time']:.1f} –º—Å"
            )

        with col2:
            avg_calls = calls_queries['calls'].mean()
            st.metric(
                "üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤",
                f"{avg_calls:.0f}",
                help="–°—Ä–µ–¥–Ω–µ–µ –ø–æ —Ç–æ–ø-10 –∑–∞–ø—Ä–æ—Å–∞–º"
            )

        with col3:
            top_3_percentage = calls_queries.head(3)['calls_percentage'].sum()
            st.metric(
                "üéØ –¢–æ–ø-3 –∑–∞–ø—Ä–æ—Å–æ–≤",
                f"{top_3_percentage:.1f}% –æ—Ç –æ–±—â–µ–≥–æ",
                help="–ü—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∑–æ–≤–æ–≤ –æ—Ç —Ç–æ–ø-3 –∑–∞–ø—Ä–æ—Å–æ–≤"
            )

        # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        st.markdown("#### üìã –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤")

        # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        display_df = queries_df.copy()

        # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        display_df['query_short'] = display_df['query'].str[:80] + '...'

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        display_df['cache_hit_ratio'] = (display_df['shared_blks_hit']
                                         / (display_df['shared_blks_hit'] + display_df['shared_blks_read'] + 1) * 100).round(1)
        display_df['total_time_minutes'] = (display_df['total_exec_time'] / 1000 / 60).round(2)
        display_df['avg_rows_per_call'] = (display_df['rows'] / display_df['calls']).round(0)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        display_df = display_df.sort_values('total_exec_time', ascending=False)

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        st.dataframe(
            display_df[['query_short', 'calls', 'total_time_minutes', 'mean_exec_time',
                       'avg_rows_per_call', 'cache_hit_ratio', 'shared_blks_hit', 'shared_blks_read']],
            width='stretch',
            hide_index=True,
            column_config={
                'query_short': st.column_config.TextColumn(
                    '–ó–∞–ø—Ä–æ—Å',
                    width='large',
                    help='SQL –∑–∞–ø—Ä–æ—Å (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π)'
                ),
                'calls': st.column_config.NumberColumn(
                    '–í—ã–∑–æ–≤—ã',
                    format='%d',
                    help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π –∑–∞–ø—Ä–æ—Å–∞'
                ),
                'total_time_minutes': st.column_config.NumberColumn(
                    '–û–±—â–µ–µ –≤—Ä–µ–º—è (–º–∏–Ω)',
                    format='%.2f',
                    help='–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–∏–Ω—É—Ç–∞—Ö'
                ),
                'mean_exec_time': st.column_config.NumberColumn(
                    '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (–º—Å)',
                    format='%.1f',
                    help='–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö'
                ),
                'avg_rows_per_call': st.column_config.NumberColumn(
                    '–°—Ç—Ä–æ–∫/–≤—ã–∑–æ–≤',
                    format='%.0f',
                    help='–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–∞ –≤—ã–∑–æ–≤'
                ),
                'cache_hit_ratio': st.column_config.NumberColumn(
                    '–ö—ç—à —Ö–∏—Ç (%)',
                    format='%.1f%%',
                    help='–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à'
                ),
                'shared_blks_hit': st.column_config.NumberColumn(
                    '–ë–ª–æ–∫–∏ –≤ –∫—ç—à–µ',
                    format='%d',
                    help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤, –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö –∏–∑ –∫—ç—à–∞'
                ),
                'shared_blks_read': st.column_config.NumberColumn(
                    '–ë–ª–æ–∫–∏ —Å –¥–∏—Å–∫–∞',
                    format='%d',
                    help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤, –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã—Ö —Å –¥–∏—Å–∫–∞'
                )
            }
        )

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_calls = display_df['calls'].sum()
            st.metric("üìû –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤", f"{total_calls:,}")

        with col2:
            total_time_minutes = display_df['total_time_minutes'].sum()
            total_time_hours = total_time_minutes / 60

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ —á–∞—Å–∞—Ö, –µ—Å–ª–∏ –±–æ–ª—å—à–µ 1 —á–∞—Å–∞, –∏–Ω–∞—á–µ –≤ –º–∏–Ω—É—Ç–∞—Ö
            if total_time_hours >= 1:
                st.metric("‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", f"{total_time_hours:.1f} —á")
            else:
                st.metric("‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", f"{total_time_minutes:.1f} –º–∏–Ω")

        with col3:
            avg_cache_hit = display_df['cache_hit_ratio'].mean()
            st.metric("üíæ –°—Ä–µ–¥–Ω–∏–π –∫—ç—à —Ö–∏—Ç", f"{avg_cache_hit:.1f}%")

        with col4:
            slowest_query_time = display_df['mean_exec_time'].max()
            st.metric("üêå –°–∞–º—ã–π –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å", f"{slowest_query_time:.1f} –º—Å")

        # LLM –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤
        _show_llm_query_analysis(queries_df)


def _show_connection_statistics(stats_data: Dict[str, Any]):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π."""
    st.markdown("### üîó –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")

    connections = stats_data.get('connections', [])

    if not connections:
        st.info("‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è—Ö")
        return

    # –°–æ–∑–¥–∞–µ–º DataFrame
    connections_df = pd.DataFrame(connections)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º
    if not connections_df.empty:
        st.markdown("#### üìä –ü–æ–¥–∫–ª—é—á–µ–Ω–∏—è –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º")

        state_counts = connections_df['state'].value_counts()

        fig_states = px.pie(
            values=state_counts.values,
            names=state_counts.index,
            title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º"
        )
        st.plotly_chart(fig_states, width='stretch')

        # –¢–∞–±–ª–∏—Ü–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        st.markdown("#### üìã –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")

        active_connections = connections_df[connections_df['state'] == 'active']

        if not active_connections.empty:
            # –£–ª—É—á—à–∞–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            display_connections = active_connections.copy()
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É timezone - –ø—Ä–∏–≤–æ–¥–∏–º –∫ naive datetime
            current_time = datetime.now()
            query_start_times = pd.to_datetime(display_connections['query_start'], utc=True).dt.tz_localize(None)
            display_connections['query_duration'] = (
                current_time - query_start_times
            ).dt.total_seconds().round(1)

            # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            display_connections['query_short'] = display_connections['query'].str[:60] + '...'

            st.dataframe(
                display_connections[['datname', 'usename', 'application_name', 'client_addr',
                                     'query_duration', 'query_short']],
                width='stretch',
                hide_index=True,
                column_config={
                    'datname': st.column_config.TextColumn(
                        '–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö',
                        width='medium',
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'
                    ),
                    'usename': st.column_config.TextColumn(
                        '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å',
                        width='medium',
                        help='–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è'
                    ),
                    'application_name': st.column_config.TextColumn(
                        '–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',
                        width='medium',
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è'
                    ),
                    'client_addr': st.column_config.TextColumn(
                        'IP –∞–¥—Ä–µ—Å',
                        width='medium',
                        help='IP –∞–¥—Ä–µ—Å –∫–ª–∏–µ–Ω—Ç–∞'
                    ),
                    'query_duration': st.column_config.NumberColumn(
                        '–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å–µ–∫)',
                        format='%.1f',
                        help='–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞'
                    ),
                    'query_short': st.column_config.TextColumn(
                        '–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å',
                        width='large',
                        help='SQL –∑–∞–ø—Ä–æ—Å (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π)'
                    )
                }
            )
        else:
            st.info("‚ÑπÔ∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")

        # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
        st.markdown("#### üìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            total_connections = len(connections_df)
            st.metric("üîó –í—Å–µ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π", total_connections)

        with col2:
            active_count = len(connections_df[connections_df['state'] == 'active'])
            st.metric("‚ö° –ê–∫—Ç–∏–≤–Ω—ã—Ö", active_count)

        with col3:
            idle_count = len(connections_df[connections_df['state'] == 'idle'])
            st.metric("üò¥ –ù–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö", idle_count)

        with col4:
            idle_in_transaction = len(connections_df[connections_df['state'] == 'idle in transaction'])
            st.metric("‚è≥ –í —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", idle_in_transaction)


def _show_load_charts(stats_data: Dict[str, Any]):
    """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏."""
    st.markdown("### üìà –ì—Ä–∞—Ñ–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏")

    # –°–æ–∑–¥–∞–µ–º mock –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    import numpy as np

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
    hours = 24
    timestamps = [datetime.now() - timedelta(hours=i) for i in range(hours, 0, -1)]

    # Mock –¥–∞–Ω–Ω—ã–µ –Ω–∞–≥—Ä—É–∑–∫–∏
    cpu_usage = np.random.normal(45, 15, hours)
    cpu_usage = np.clip(cpu_usage, 0, 100)

    memory_usage = np.random.normal(60, 10, hours)
    memory_usage = np.clip(memory_usage, 0, 100)

    # –°–æ–∑–¥–∞–µ–º DataFrame
    load_df = pd.DataFrame({
        'timestamp': timestamps,
        'cpu_usage': cpu_usage,
        'memory_usage': memory_usage
    })

    # –ì—Ä–∞—Ñ–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏ CPU
    fig_cpu = go.Figure()
    fig_cpu.add_trace(go.Scatter(
        x=load_df['timestamp'],
        y=load_df['cpu_usage'],
        mode='lines+markers',
        name='CPU Usage',
        line=dict(color='#336791', width=2)
    ))
    fig_cpu.update_layout(
        title="–ù–∞–≥—Ä—É–∑–∫–∞ CPU (%)",
        xaxis_title="–í—Ä–µ–º—è",
        yaxis_title="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU (%)",
        height=300
    )
    st.plotly_chart(fig_cpu, width='stretch')

    # –ì—Ä–∞—Ñ–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
    fig_memory = go.Figure()
    fig_memory.add_trace(go.Scatter(
        x=load_df['timestamp'],
        y=load_df['memory_usage'],
        mode='lines+markers',
        name='Memory Usage',
        line=dict(color='#4a90a4', width=2)
    ))
    fig_memory.update_layout(
        title="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (%)",
        xaxis_title="–í—Ä–µ–º—è",
        yaxis_title="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (%)",
        height=300
    )
    st.plotly_chart(fig_memory, width='stretch')


def _show_mock_statistics():
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç mock —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
    st.markdown("### üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (Mock)")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(label="üîó –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è", value=12)

    with col2:
        st.metric(label="‚ö° –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã", value=3)

    with col3:
        st.metric(label="üò¥ –ù–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è", value=8)

    with col4:
        st.metric(label="‚è≥ –í —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", value=1)

    st.markdown("### üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ (Mock)")

    # Mock –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–æ–≤
    mock_queries = pd.DataFrame({
        'query': [
            'SELECT * FROM users WHERE id = $1',
            'SELECT COUNT(*) FROM orders WHERE created_at > $1',
            'UPDATE products SET price = $1 WHERE id = $2',
            'INSERT INTO logs (message, level) VALUES ($1, $2)',
            'SELECT u.name, o.total FROM users u JOIN orders o ON u.id = o.user_id'
        ],
        'calls': [1250, 890, 450, 320, 180],
        'total_time': [12500, 8900, 4500, 3200, 1800],
        'mean_time': [10.0, 10.0, 10.0, 10.0, 10.0],
        'rows': [1250, 890, 450, 320, 180]
    })

    st.dataframe(mock_queries, width='stretch', hide_index=True)

    st.markdown("### üîó –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π (Mock)")

    # Mock –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
    mock_sessions = pd.DataFrame({
        'datname': ['postgres', 'postgres', 'postgres', 'postgres'],
        'usename': ['postgres', 'app_user', 'readonly_user', 'admin'],
        'application_name': ['psql', 'web_app', 'analytics', 'backup'],
        'client_addr': ['127.0.0.1', '192.168.1.100', '192.168.1.101', '10.0.0.5'],
        'state': ['active', 'idle', 'active', 'idle in transaction'],
        'query_start': [
            datetime.now() - timedelta(minutes=5),
            datetime.now() - timedelta(minutes=10),
            datetime.now() - timedelta(minutes=2),
            datetime.now() - timedelta(minutes=15)
        ]
    })

    st.dataframe(mock_sessions, width='stretch', hide_index=True)

    st.markdown("### üìà –ì—Ä–∞—Ñ–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ (Mock)")

    # Mock –≥—Ä–∞—Ñ–∏–∫
    import numpy as np

    hours = 24
    timestamps = [datetime.now() - timedelta(hours=i) for i in range(hours, 0, -1)]
    cpu_usage = np.random.normal(45, 15, hours)
    cpu_usage = np.clip(cpu_usage, 0, 100)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=timestamps,
        y=cpu_usage,
        mode='lines+markers',
        name='CPU Usage',
        line=dict(color='#336791', width=2)
    ))
    fig.update_layout(
        title="–ù–∞–≥—Ä—É–∑–∫–∞ CPU (%) - Mock –¥–∞–Ω–Ω—ã–µ",
        xaxis_title="–í—Ä–µ–º—è",
        yaxis_title="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU (%)",
        height=400
    )
    st.plotly_chart(fig, width='stretch')


def _show_llm_query_analysis(queries_df: pd.DataFrame):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç LLM –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ."""
    st.markdown("#### ü§ñ AI –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ AI
    if not st.session_state.get('enable_ai', False):
        st.info("‚ÑπÔ∏è AI –∞–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª—é—á–µ–Ω. –í–∫–ª—é—á–∏—Ç–µ AI –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤.")
        return

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if 'statistics_analyzed' not in st.session_state:
        with st.spinner("ü§ñ AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å—ã..."):
            try:
                import asyncio
                from app.llm_integration import LLMIntegration

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
                api_key = st.session_state.get('openai_api_key', '')
                if not api_key:
                    st.error("""‚ùå **OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω**

üí° **–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á:**
1. –û—Ç–∫—Ä–æ–π—Ç–µ sidebar (–ª–µ–≤–∞—è –ø–∞–Ω–µ–ª—å)
2. –ù–∞–π–¥–∏—Ç–µ —Ä–∞–∑–¥–µ–ª "ü§ñ AI –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"
3. –í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenAI API –∫–ª—é—á –≤ –ø–æ–ª–µ "OpenAI API –∫–ª—é—á"

üîó **–ì–¥–µ –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á:**
- –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ https://platform.openai.com/api-keys
- –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π API –∫–ª—é—á
- –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

‚öôÔ∏è **–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
- –ú–æ–¥–µ–ª—å: {st.session_state.get('openai_model', 'gpt-4o-mini')}""")
                    st.session_state['statistics_analyzed'] = True
                    return

                # –ë–µ—Ä–µ–º —Ç–æ–ø-5 —Å–∞–º—ã—Ö –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                top_queries = queries_df.head(5)

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                analysis_data = []
                for _, row in top_queries.iterrows():
                    analysis_data.append({
                        'query': row['query'][:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                        'calls': row['calls'],
                        'mean_exec_time': row['mean_exec_time'],
                        'total_exec_time': row['total_exec_time'],
                        'rows': row['rows'],
                        'shared_blks_hit': row['shared_blks_hit'],
                        'shared_blks_read': row['shared_blks_read']
                    })

                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                prompt = f"""
                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã PostgreSQL –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
                
                –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:
                {json.dumps(analysis_data, indent=2, ensure_ascii=False)}
                
                –ù–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
                ### –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.
                –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –≤—ã—Å–æ–∫–∏–π/—Å—Ä–µ–¥–Ω–∏–π/–Ω–∏–∑–∫–∏–π
                –ö–∞—Ç–µ–≥–æ—Ä–∏—è: query_optimization/index_optimization/configuration_optimization
                –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è
                –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: –û–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π
                –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0.0-1.0
                ---
                
                –î–∞–π 3-5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∞–º—ã—Ö –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
                """

                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
                llm_config = {
                    'openai_api_key': api_key,
                    'openai_model': st.session_state.get('openai_model', 'gpt-4o-mini'),
                    'openai_temperature': 0.3,
                    'enable_proxy': st.session_state.get('enable_proxy', True),
                    'proxy_host': st.session_state.get('proxy_host', 'localhost'),
                    'proxy_port': st.session_state.get('proxy_port', 1080)
                }

                llm = LLMIntegration(llm_config)

                # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π execution_plan –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
                mock_execution_plan = {
                    'type': 'query_analysis',
                    'queries': analysis_data,
                    'prompt': prompt
                }

                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
                async def get_async_recommendations():
                    return await llm.get_recommendations(
                        sql_query=prompt,
                        execution_plan=mock_execution_plan,
                        db_schema=analysis_data
                    )

                # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
                recommendations = asyncio.run(get_async_recommendations())

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ session_state
                if recommendations:
                    st.session_state['statistics_analysis'] = recommendations
                else:
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç AI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API –∫–ª—é—á–µ–π –∏ –ø—Ä–æ–∫—Å–∏.")

                st.session_state['statistics_analyzed'] = True

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ LLM –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
                error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {str(e)}"

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
                if "401" in str(e) or "unauthorized" in str(e).lower():
                    error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á OpenAI"
                    error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö sidebar"
                elif "403" in str(e) or "forbidden" in str(e).lower():
                    error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** API –∫–ª—é—á –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ OpenAI API"
                    error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ API –∫–ª—é—á–∞"
                elif "httpx" in str(e):
                    error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ httpx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
                    error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ httpx: `pip install httpx[socks]`"
                elif "proxy" in str(e).lower():
                    error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–æ–∫—Å–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"
                    error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏ –≤ sidebar"
                elif "timeout" in str(e).lower():
                    error_msg += "\n\nüí° **–ü—Ä–æ–±–ª–µ–º–∞:** –¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"
                    error_msg += "\nüîß **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∫—Å–∏"
                else:
                    error_msg += "\n\nüí° **–û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**"
                    error_msg += "\n- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á OpenAI"
                    error_msg += "\n- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—Ä–æ–∫—Å–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)"
                    error_msg += "\n- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ"

                st.error(error_msg)
                st.session_state['statistics_analyzed'] = True

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if 'statistics_analysis' in st.session_state:
        st.markdown("#### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤")
        _display_llm_analysis(st.session_state['statistics_analysis'])

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑", help="–ü–æ–≤—Ç–æ—Ä–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–æ–≤"):
        st.session_state['statistics_analyzed'] = False
        st.rerun()


def _display_llm_analysis(recommendations):
    """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç LLM –∞–Ω–∞–ª–∏–∑–∞."""
    try:
        if not recommendations:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç AI")
            return

        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        for rec in recommendations:
            priority = rec.priority if hasattr(rec, 'priority') else '—Å—Ä–µ–¥–Ω–∏–π'
            category = rec.category if hasattr(rec, 'category') else 'query_optimization'
            description = rec.description if hasattr(rec, 'description') else ''
            expected_improvement = rec.expected_improvement if hasattr(rec, 'expected_improvement') else ''
            confidence = rec.confidence if hasattr(rec, 'confidence') else 0.5
            reasoning = rec.reasoning if hasattr(rec, 'reasoning') else ''

            # –≠–º–æ–¥–∑–∏ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            priority_emoji = "üî¥" if priority == "–≤—ã—Å–æ–∫–∏–π" else "üü°" if priority == "—Å—Ä–µ–¥–Ω–∏–π" else "üü¢"

            st.markdown(f"### {priority_emoji} {description}")

            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {priority}")
                st.markdown(f"**–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {category}")
            with col2:
                st.markdown(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {confidence:.1%}")

            if reasoning:
                st.markdown(f"**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {reasoning}")

            if expected_improvement:
                st.markdown(f"**–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ:** {expected_improvement}")

            st.markdown("---")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è LLM –∞–Ω–∞–ª–∏–∑–∞: {e}")
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
