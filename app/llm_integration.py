"""
–ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≤–Ω–µ—à–Ω–∏–º–∏ LLM –¥–ª—è AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ë–î.
"""

import json
import logging
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import requests

logger = logging.getLogger(__name__)


@dataclass
class LLMRecommendation:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
    type: str = "ai_recommendation"
    priority: str = "medium"
    category: str = "general"
    description: str = ""
    current_query: str = ""
    optimized_query: str = ""
    expected_improvement: str = ""
    reasoning: str = ""
    llm_model: str = ""
    confidence: float = 0.0
    additional_suggestions: List[str] = None

    def __post_init__(self):
        if self.additional_suggestions is None:
            self.additional_suggestions = []


class LLMProvider(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤."""

    @abstractmethod
    async def get_recommendations(
            self,
            sql_query: str,
            execution_plan: Dict,
            db_schema: Optional[Dict] = None) -> List[LLMRecommendation]:
        """–ü–æ–ª—É—á–∏—Ç—å AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞."""

    @abstractmethod
    async def analyze_database_schema(
            self, schema: Dict) -> List[LLMRecommendation]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã –ë–î –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π."""

    @abstractmethod
    async def optimize_query(self, sql_query: str, context: Dict) -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é AI."""


class OpenAIProvider(LLMProvider):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI GPT."""

    def __init__(
            self,
            api_key: str,
            model: str = "gpt-4",
            temperature: float = 0.7,
            enable_proxy: bool = False,
            proxy_host: str = "localhost",
            proxy_port: int = 1080):
        self.api_key = api_key
        self.model = model
        self.temperature = temperature
        self.base_url = "https://api.openai.com/v1"
        self.enable_proxy = enable_proxy
        self.proxy_host = proxy_host
        self.proxy_port = proxy_port

    async def get_recommendations(
            self,
            sql_query: str,
            execution_plan: Dict,
            db_schema: Optional[Dict] = None) -> List[LLMRecommendation]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç OpenAI GPT."""
        try:
            prompt = self._build_analysis_prompt(
                sql_query, execution_plan, db_schema)

            response = await self._call_openai_api(prompt)

            return self._parse_recommendations(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç OpenAI: {e}")
            return []

    async def analyze_database_schema(
            self, schema: Dict) -> List[LLMRecommendation]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã –ë–î —Å –ø–æ–º–æ—â—å—é OpenAI."""
        try:
            prompt = self._build_schema_analysis_prompt(schema)

            response = await self._call_openai_api(prompt)

            return self._parse_schema_recommendations(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î OpenAI: {e}")
            return []

    async def optimize_query(self, sql_query: str, context: Dict) -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ OpenAI."""
        try:
            prompt = self._build_optimization_prompt(sql_query, context)

            response = await self._call_openai_api(prompt)

            return self._extract_optimized_query(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ OpenAI: {e}")
            return sql_query

    def _build_analysis_prompt(self, sql_query: str, execution_plan: Dict,
                               db_schema: Optional[Dict] = None) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ SQL."""
        prompt = f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ PostgreSQL. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL –∑–∞–ø—Ä–æ—Å –∏ –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

        SQL –∑–∞–ø—Ä–æ—Å:
        {sql_query}

        –ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        {json.dumps(execution_plan, indent=2, ensure_ascii=False)}
        """

        if db_schema:
            prompt += f"\n–°—Ö–µ–º–∞ –ë–î:\n{
                json.dumps(
                    db_schema,
                    indent=2,
                    ensure_ascii=False)}"

        prompt += """

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
          "recommendations": [
            {
              "priority": "high|medium|low",
              "category": "query_optimization|index_optimization|schema_optimization",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
              "current_query": "–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å",
              "optimized_query": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
              "expected_improvement": "–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
              "confidence": 0.85
            }
          ]
        }
        """

        return prompt

    def _build_schema_analysis_prompt(self, schema: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î."""
        return f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –ë–î. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ö–µ–º—É PostgreSQL.

        –°—Ö–µ–º–∞ –ë–î:
        {json.dumps(schema, indent=2, ensure_ascii=False)}

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å—Ö–µ–º—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
          "recommendations": [
            {{
              "priority": "high|medium|low",
              "category": "normalization|data_types|indexing|partitioning",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏—è",
              "suggestion": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
              "expected_benefit": "–û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–ª—å–∑–∞",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ",
              "confidence": 0.85
            }}
          ]
        }}
        """

    def _build_optimization_prompt(self, sql_query: str, context: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞."""
        return f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ SQL. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å:

        –ó–∞–ø—Ä–æ—Å:
        {sql_query}

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {json.dumps(context, indent=2, ensure_ascii=False)}

        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
        """

    async def _call_openai_api(self, prompt: str) -> str:
        """–í—ã–∑–æ–≤ OpenAI API."""
        import os
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ PostgreSQL. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ù–ï –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Ç–∏–ø–∞ '## ü§ñ AI –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'. –ù–∞—á–∏–Ω–∞–π —Å—Ä–∞–∑—É —Å '### –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.'"},
                {"role": "user", "content": prompt}
            ],
            "temperature": self.temperature,
            "max_tokens": 2000
        }

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
        if self.enable_proxy:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º httpx –¥–ª—è SOCKS5 –ø–æ–¥–¥–µ—Ä–∂–∫–∏
                import httpx
                proxy_url = f"socks5://{self.proxy_host}:{self.proxy_port}"
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è SOCKS5 –ø—Ä–æ–∫—Å–∏: {proxy_url}")
                
                async with httpx.AsyncClient(proxy=proxy_url, timeout=30.0) as client:
                    response = await client.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=data
                    )
                    response.raise_for_status()
                    return response.json()["choices"][0]["message"]["content"]
                    
            except ImportError:
                logger.warning("httpx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º requests –±–µ–∑ SOCKS5")
                # Fallback –∫ requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                )
                response.raise_for_status()
                return response.json()["choices"][0]["message"]["content"]
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
                # Fallback –∫ requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=30
                )
                response.raise_for_status()
                return response.json()["choices"][0]["message"]["content"]
        else:
            # –ü—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑ –ø—Ä–æ–∫—Å–∏
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]

    def _parse_recommendations(self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –æ—Ç–≤–µ—Ç–∞ OpenAI."""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "general"),
                    description=rec.get("description", ""),
                    current_query=rec.get("current_query", ""),
                    optimized_query=rec.get("optimized_query", ""),
                    expected_improvement=rec.get("expected_improvement", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0)
                )
                recommendations.append(recommendation)

            return recommendations

        except json.JSONDecodeError:
            # –ï—Å–ª–∏ –Ω–µ JSON, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞
            logger.info("OpenAI –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å JSON")
            
            # –ò—â–µ–º JSON –±–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                try:
                    json_str = json_match.group(1)
                    data = json.loads(json_str)
                    recommendations = []

                    for rec in data.get("recommendations", []):
                        recommendation = LLMRecommendation(
                            priority=rec.get("priority", "medium"),
                            category=rec.get("category", "general"),
                            description=rec.get("description", ""),
                            current_query=rec.get("current_query", ""),
                            optimized_query=rec.get("optimized_query", ""),
                            expected_improvement=rec.get("expected_improvement", ""),
                            reasoning=rec.get("reasoning", ""),
                            llm_model=self.model,
                            confidence=rec.get("confidence", 0.0)
                        )
                        recommendations.append(recommendation)

                    return recommendations
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –∏–∑ —Ç–µ–∫—Å—Ç–∞: {e}")
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON, —Å–æ–∑–¥–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            recommendation = LLMRecommendation(
                priority="medium",
                category="general",
                description="AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ PostgreSQL",
                current_query="",
                optimized_query="",
                expected_improvement="",
                reasoning=response,
                llm_model=self.model,
                confidence=0.8
            )
            return [recommendation]

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π OpenAI: {e}")
            return []

    def _parse_schema_recommendations(
            self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ –ë–î."""
        try:
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "schema_optimization"),
                    description=rec.get("description", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0),
                    additional_suggestions=[rec.get("suggestion", "")]
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ: {e}")
            return []

    def _extract_optimized_query(self, response: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞."""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        query = response.strip()
        if query.startswith("```sql"):
            query = query[7:]
        if query.endswith("```"):
            query = query[:-3]

        return query.strip()


class AnthropicProvider(LLMProvider):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Anthropic Claude."""

    def __init__(self, api_key: str, model: str = "claude-3-sonnet"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.anthropic.com/v1"

    async def get_recommendations(
            self,
            sql_query: str,
            execution_plan: Dict,
            db_schema: Optional[Dict] = None) -> List[LLMRecommendation]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç Anthropic Claude."""
        try:
            prompt = self._build_analysis_prompt(
                sql_query, execution_plan, db_schema)

            response = await self._call_anthropic_api(prompt)

            return self._parse_recommendations(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç Anthropic: {e}")
            return []

    async def analyze_database_schema(
            self, schema: Dict) -> List[LLMRecommendation]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã –ë–î —Å –ø–æ–º–æ—â—å—é Anthropic."""
        try:
            prompt = self._build_schema_analysis_prompt(schema)

            response = await self._call_anthropic_api(prompt)

            return self._parse_schema_recommendations(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î Anthropic: {e}")
            return []

    async def optimize_query(self, sql_query: str, context: Dict) -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ Anthropic."""
        try:
            prompt = self._build_optimization_prompt(sql_query, context)

            response = await self._call_anthropic_api(prompt)

            return self._extract_optimized_query(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ Anthropic: {e}")
            return sql_query

    def _build_analysis_prompt(self, sql_query: str, execution_plan: Dict,
                               db_schema: Optional[Dict] = None) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ SQL."""
        prompt = f"""
        <system>
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ PostgreSQL. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL –∑–∞–ø—Ä–æ—Å –∏ –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
        </system>

        <user>
        SQL –∑–∞–ø—Ä–æ—Å:
        {sql_query}

        –ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        {json.dumps(execution_plan, indent=2, ensure_ascii=False)}
        """

        if db_schema:
            prompt += f"\n–°—Ö–µ–º–∞ –ë–î:\n{
                json.dumps(
                    db_schema,
                    indent=2,
                    ensure_ascii=False)}"

        prompt += """

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
          "recommendations": [
            {
              "priority": "high|medium|low",
              "category": "query_optimization|index_optimization|schema_optimization",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
              "current_query": "–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å",
              "optimized_query": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
              "expected_improvement": "–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
              "confidence": 0.85
            }
          ]
        }
        </user>
        """

        return prompt

    def _build_schema_analysis_prompt(self, schema: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î."""
        return f"""
        <system>
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –ë–î. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ö–µ–º—É PostgreSQL.
        </system>

        <user>
        –°—Ö–µ–º–∞ –ë–î:
        {json.dumps(schema, indent=2, ensure_ascii=False)}

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å—Ö–µ–º—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
          "recommendations": [
            {{
              "priority": "high|medium|low",
              "category": "normalization|data_types|indexing|partitioning",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏—è",
              "suggestion": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
              "expected_benefit": "–û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–ª—å–∑–∞",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ",
              "confidence": 0.85
            }}
          ]
        }}
        </user>
        """

    def _build_optimization_prompt(self, sql_query: str, context: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞."""
        return f"""
        <system>
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ SQL. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å.
        </system>

        <user>
        –ó–∞–ø—Ä–æ—Å:
        {sql_query}

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {json.dumps(context, indent=2, ensure_ascii=False)}

        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
        </user>
        """

    async def _call_anthropic_api(self, prompt: str) -> str:
        """–í—ã–∑–æ–≤ Anthropic API."""
        headers = {
            "x-api-key": self.api_key,
            "Content-Type": "application/json",
            "anthropic-version": "2023-06-01"
        }

        data = {
            "model": self.model,
            "max_tokens": 2000,
            "messages": [{"role": "user", "content": prompt}]
        }

        response = requests.post(
            f"{self.base_url}/messages",
            headers=headers,
            json=data,
            timeout=30
        )

        response.raise_for_status()

        return response.json()["content"][0]["text"]

    def _parse_recommendations(self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –æ—Ç–≤–µ—Ç–∞ Anthropic."""
        try:
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "general"),
                    description=rec.get("description", ""),
                    current_query=rec.get("current_query", ""),
                    optimized_query=rec.get("optimized_query", ""),
                    expected_improvement=rec.get("expected_improvement", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0)
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π Anthropic: {e}")
            return []

    def _parse_schema_recommendations(
            self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ –ë–î."""
        try:
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "schema_optimization"),
                    description=rec.get("description", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0),
                    additional_suggestions=[rec.get("suggestion", "")]
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ: {e}")
            return []

    def _extract_optimized_query(self, response: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞."""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        query = response.strip()
        if query.startswith("```sql"):
            query = query[7:]
        if query.endswith("```"):
            query = query[:-3]

        return query.strip()


class LocalLLMProvider(LLMProvider):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ LLM (Ollama, LM Studio)."""

    def __init__(self, base_url: str, model: str):
        self.base_url = base_url.rstrip('/')
        self.model = model

    async def get_recommendations(
            self,
            sql_query: str,
            execution_plan: Dict,
            db_schema: Optional[Dict] = None) -> List[LLMRecommendation]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM."""
        try:
            prompt = self._build_analysis_prompt(
                sql_query, execution_plan, db_schema)

            response = await self._call_local_api(prompt)

            return self._parse_recommendations(response)

        except Exception as e:
            logger.error(
                f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
            return []

    async def analyze_database_schema(
            self, schema: Dict) -> List[LLMRecommendation]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã –ë–î —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π LLM."""
        try:
            prompt = self._build_schema_analysis_prompt(schema)

            response = await self._call_local_api(prompt)

            return self._parse_schema_recommendations(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
            return []

    async def optimize_query(self, sql_query: str, context: Dict) -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM."""
        try:
            prompt = self._build_optimization_prompt(sql_query, context)

            response = await self._call_local_api(prompt)

            return self._extract_optimized_query(response)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
            return sql_query

    def _build_analysis_prompt(self, sql_query: str, execution_plan: Dict,
                               db_schema: Optional[Dict] = None) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ SQL."""
        prompt = f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ PostgreSQL. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π SQL –∑–∞–ø—Ä–æ—Å –∏ –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

        SQL –∑–∞–ø—Ä–æ—Å:
        {sql_query}

        –ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        {json.dumps(execution_plan, indent=2, ensure_ascii=False)}
        """

        if db_schema:
            prompt += f"\n–°—Ö–µ–º–∞ –ë–î:\n{
                json.dumps(
                    db_schema,
                    indent=2,
                    ensure_ascii=False)}"

        prompt += """

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {
          "recommendations": [
            {
              "priority": "high|medium|low",
              "category": "query_optimization|index_optimization|schema_optimization",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
              "current_query": "–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å",
              "optimized_query": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
              "expected_improvement": "–û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
              "confidence": 0.85
            }
          ]
        }
        """

        return prompt

    def _build_schema_analysis_prompt(self, schema: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î."""
        return f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –ë–î. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ö–µ–º—É PostgreSQL.

        –°—Ö–µ–º–∞ –ë–î:
        {json.dumps(schema, indent=2, ensure_ascii=False)}

        –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Å—Ö–µ–º—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
        {{
          "recommendations": [
            {{
              "priority": "high|medium|low",
              "category": "normalization|data_types|indexing|partitioning",
              "description": "–û–ø–∏—Å–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏—è",
              "suggestion": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
              "expected_benefit": "–û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–ª—å–∑–∞",
              "reasoning": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ",
              "confidence": 0.85
            }}
          ]
        }}
        """

    def _build_optimization_prompt(self, sql_query: str, context: Dict) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞."""
        return f"""
        –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ SQL. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å:

        –ó–∞–ø—Ä–æ—Å:
        {sql_query}

        –ö–æ–Ω—Ç–µ–∫—Å—Ç:
        {json.dumps(context, indent=2, ensure_ascii=False)}

        –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
        """

    async def _call_local_api(self, prompt: str) -> str:
        """–í—ã–∑–æ–≤ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ LLM API."""
        # –ü–æ–ø—Ä–æ–±—É–µ–º Ollama —Ñ–æ—Ä–º–∞—Ç
        try:
            data = {
                "model": self.model,
                "prompt": prompt,
                "stream": False
            }

            response = requests.post(
                f"{self.base_url}/api/generate",
                json=data,
                timeout=60
            )

            response.raise_for_status()

            return response.json()["response"]

        except Exception:
            # –ü–æ–ø—Ä–æ–±—É–µ–º LM Studio —Ñ–æ—Ä–º–∞—Ç
            try:
                data = {
                    "model": self.model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7,
                    "max_tokens": 2000
                }

                response = requests.post(
                    f"{self.base_url}/v1/chat/completions",
                    json=data,
                    timeout=60
                )

                response.raise_for_status()

                return response.json()["choices"][0]["message"]["content"]

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ LLM API: {e}")
                raise

    def _parse_recommendations(self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ –æ—Ç–≤–µ—Ç–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM."""
        try:
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "general"),
                    description=rec.get("description", ""),
                    current_query=rec.get("current_query", ""),
                    optimized_query=rec.get("optimized_query", ""),
                    expected_improvement=rec.get("expected_improvement", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0)
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ª–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}")
            return []

    def _parse_schema_recommendations(
            self, response: str) -> List[LLMRecommendation]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ –ë–î."""
        try:
            data = json.loads(response)
            recommendations = []

            for rec in data.get("recommendations", []):
                recommendation = LLMRecommendation(
                    priority=rec.get("priority", "medium"),
                    category=rec.get("category", "schema_optimization"),
                    description=rec.get("description", ""),
                    reasoning=rec.get("reasoning", ""),
                    llm_model=self.model,
                    confidence=rec.get("confidence", 0.0),
                    additional_suggestions=[rec.get("suggestion", "")]
                )
                recommendations.append(recommendation)

            return recommendations

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ö–µ–º–µ: {e}")
            return []

    def _extract_optimized_query(self, response: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞."""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        query = response.strip()
        if query.startswith("```sql"):
            query = query[7:]
        if query.endswith("```"):
            query = query[:-3]

        return query.strip()


class LLMIntegration:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å LLM."""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.providers = {}
        self._initialize_providers()

    def _initialize_providers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤."""
        # OpenAI
        if self.config.get("openai_api_key"):
            self.providers["openai"] = OpenAIProvider(
                api_key=self.config["openai_api_key"],
                model=self.config.get("openai_model", "gpt-4"),
                temperature=self.config.get("openai_temperature", 0.7),
                enable_proxy=self.config.get("enable_proxy", False),
                proxy_host=self.config.get("proxy_host", "localhost"),
                proxy_port=self.config.get("proxy_port", 1080)
            )

        # Anthropic
        if self.config.get("anthropic_api_key"):
            self.providers["anthropic"] = AnthropicProvider(
                api_key=self.config["anthropic_api_key"],
                model=self.config.get("anthropic_model", "claude-3-sonnet")
            )

        # –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        if self.config.get("local_llm_url") and self.config.get(
                "local_llm_model"):
            self.providers["local"] = LocalLLMProvider(
                base_url=self.config["local_llm_url"],
                model=self.config["local_llm_model"]
            )

    async def get_recommendations(
            self,
            sql_query: str,
            execution_plan: Dict,
            db_schema: Optional[Dict] = None,
            provider: str = "auto") -> List[LLMRecommendation]:
        """–ü–æ–ª—É—á–∏—Ç—å AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."""
        if not self.providers:
            logger.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
            return []

        if provider == "auto":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            provider = list(self.providers.keys())[0]

        if provider not in self.providers:
            logger.error(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []

        try:
            return await self.providers[provider].get_recommendations(
                sql_query, execution_plan, db_schema
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç {provider}: {e}")
            return []

    async def analyze_database_schema(
            self,
            schema: Dict,
            provider: str = "auto") -> List[LLMRecommendation]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã –ë–î —Å –ø–æ–º–æ—â—å—é AI."""
        if not self.providers:
            logger.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
            return []

        if provider == "auto":
            provider = list(self.providers.keys())[0]

        if provider not in self.providers:
            logger.error(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []

        try:
            return await self.providers[provider].analyze_database_schema(schema)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã –ë–î {provider}: {e}")
            return []

    async def optimize_query(self, sql_query: str, context: Dict,
                             provider: str = "auto") -> str:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é AI."""
        if not self.providers:
            logger.warning("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
            return sql_query

        if provider == "auto":
            provider = list(self.providers.keys())[0]

        if provider not in self.providers:
            logger.error(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return sql_query

        try:
            return await self.providers[provider].optimize_query(sql_query, context)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ {provider}: {e}")
            return sql_query

    def get_available_providers(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤."""
        return list(self.providers.keys())

    def is_provider_available(self, provider: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
        return provider in self.providers

    async def analyze_query_performance(self, prompt: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é LLM."""
        try:
            if not self.providers:
                logger.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
                return ""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            provider_name = list(self.providers.keys())[0]
            provider = self.providers[provider_name]
            
            logger.info(f"–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é {provider_name}")
            
            # –í—ã–∑—ã–≤–∞–µ–º LLM —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
            if provider_name == "openai":
                response = await provider._call_openai_api(prompt)
            elif provider_name == "anthropic":
                response = await provider._call_anthropic_api(prompt)
            elif provider_name == "local":
                response = await provider._call_local_api(prompt)
            else:
                logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {provider_name}")
                return ""
            
            if response:
                logger.info("–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤")
                return response
            else:
                logger.warning("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
                return ""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
            return ""
